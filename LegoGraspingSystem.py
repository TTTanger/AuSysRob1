#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¹é«˜ç§¯æœ¨è¯†åˆ«å’ŒæŠ“å–ç³»ç»Ÿ
æ•´åˆæ‰‹çœ¼æ ‡å®šã€é€†è¿åŠ¨å­¦ã€æ­£å‘æ§åˆ¶å’Œæœºæ¢°è¯¯å·®è¡¥å¿
"""

import cv2
import numpy as np
import time
import os
from typing import Tuple, Optional, List
import sys

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from HandEyeCalibration import HandEyeCalibration
from ForwardController import BraccioRobot
from InverseKinematic import inverse_kinematics
from RobotCompensation import (
    apply_joint_compensation, apply_position_compensation,
    GRIP_HEIGHT, GRIPPER_OPEN_ANGLE, GRIPPER_CLOSE_ANGLE, GRIPPER_GRAB_ANGLE,
    MOVE_TIME, CAMERA_INDEX, SAFE_HEIGHT, WORKTABLE_HEIGHT,
    DEBUG_MODE, SHOW_CAMERA_FEED, SAVE_DETECTION_IMAGES, IMAGE_SAVE_PATH,
    SERIAL_PORT, BAUD_RATE, TIMEOUT, print_compensation_status
)

class LegoGraspingSystem:
    """
    ä¹é«˜ç§¯æœ¨è¯†åˆ«å’ŒæŠ“å–ç³»ç»Ÿä¸»ç±»
    """
    
    def __init__(self, camera_index: int = CAMERA_INDEX, 
                 serial_port: str = SERIAL_PORT,
                 baud_rate: int = BAUD_RATE,
                 timeout: int = TIMEOUT):
        """
        åˆå§‹åŒ–ç³»ç»Ÿ
        
        Args:
            camera_index: æ‘„åƒå¤´ç´¢å¼•
            serial_port: ä¸²å£å·
            baud_rate: æ³¢ç‰¹ç‡
            timeout: è¶…æ—¶æ—¶é—´
        """
        self.camera_index = camera_index
        self.serial_port = serial_port
        self.baud_rate = baud_rate
        self.timeout = timeout
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.calibration = HandEyeCalibration(camera_index)
        self.robot = BraccioRobot(serial_port, baud_rate, timeout)
        self.cap = None
        
        # ç³»ç»ŸçŠ¶æ€
        self.is_calibrated = False
        self.is_robot_connected = False
        self.is_camera_open = False
        
        # åˆ›å»ºå›¾åƒä¿å­˜ç›®å½•
        if SAVE_DETECTION_IMAGES:
            os.makedirs(IMAGE_SAVE_PATH, exist_ok=True)
        
        print("ğŸ¤– ä¹é«˜ç§¯æœ¨è¯†åˆ«å’ŒæŠ“å–ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print_compensation_status()
    
    def initialize_system(self) -> bool:
        """
        åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶
        
        Returns:
            bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
        """
        print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶...")
        
        # æ£€æŸ¥æœºæ¢°è‡‚è¿æ¥
        if self.robot.s and self.robot.s.is_open:
            self.is_robot_connected = True
            print("âœ… æœºæ¢°è‡‚è¿æ¥æ­£å¸¸")
        else:
            print("âŒ æœºæ¢°è‡‚è¿æ¥å¤±è´¥")
            return False
        
        # æ‰“å¼€æ‘„åƒå¤´
        if self.open_camera():
            self.is_camera_open = True
            print("âœ… æ‘„åƒå¤´æ‰“å¼€æˆåŠŸ")
        else:
            print("âŒ æ‘„åƒå¤´æ‰“å¼€å¤±è´¥")
            return False
        
        return True
    
    def open_camera(self) -> bool:
        """
        æ‰“å¼€æ‘„åƒå¤´
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ‰“å¼€æ‘„åƒå¤´
        """
        try:
            self.cap = cv2.VideoCapture(self.camera_index)
            if not self.cap.isOpened():
                print(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {self.camera_index}")
                return False
            return True
        except Exception as e:
            print(f"âŒ æ‰“å¼€æ‘„åƒå¤´æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def close_camera(self):
        """å…³é—­æ‘„åƒå¤´"""
        if self.cap and self.cap.isOpened():
            self.cap.release()
            self.is_camera_open = False
            print("ğŸ“· æ‘„åƒå¤´å·²å…³é—­")
    
    def detect_red_lego(self, frame) -> Optional[Tuple[int, int]]:
        """
        æ£€æµ‹çº¢è‰²ä¹é«˜ç§¯æœ¨
        
        Args:
            frame: è¾“å…¥å›¾åƒå¸§
            
        Returns:
            Optional[Tuple[int, int]]: æ£€æµ‹åˆ°çš„çº¢è‰²ç§¯æœ¨ä¸­å¿ƒåƒç´ åæ ‡
        """
        # è½¬æ¢åˆ°HSVè‰²å½©ç©ºé—´
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        
        # å®šä¹‰çº¢è‰²èŒƒå›´ï¼ˆHSVï¼‰
        lower_red1 = np.array([0, 100, 100])
        upper_red1 = np.array([10, 255, 255])
        lower_red2 = np.array([160, 100, 100])
        upper_red2 = np.array([180, 255, 255])
        
        # åˆ›å»ºçº¢è‰²æ©ç 
        mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
        mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
        mask = mask1 + mask2
        
        # å½¢æ€å­¦æ“ä½œå»é™¤å™ªå£°
        kernel = np.ones((5, 5), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if contours:
            # æ‰¾åˆ°æœ€å¤§çš„è½®å»“ï¼ˆå‡è®¾æ˜¯ä¹é«˜ç§¯æœ¨ï¼‰
            largest_contour = max(contours, key=cv2.contourArea)
            area = cv2.contourArea(largest_contour)
            
            # é¢ç§¯é˜ˆå€¼ï¼Œè¿‡æ»¤æ‰å¤ªå°çš„åŒºåŸŸ
            if area > 1000:  # å¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
                # è®¡ç®—è½®å»“çš„ä¸­å¿ƒç‚¹
                M = cv2.moments(largest_contour)
                if M["m00"] != 0:
                    cx = int(M["m10"] / M["m00"])
                    cy = int(M["m01"] / M["m00"])
                    return (cx, cy)
        
        return None
    
    def perform_hand_eye_calibration(self) -> bool:
        """
        æ‰§è¡Œæ‰‹çœ¼æ ‡å®š
        
        Returns:
            bool: æ ‡å®šæ˜¯å¦æˆåŠŸ
        """
        print("\n" + "="*60)
        print("ğŸ”§ å¼€å§‹æ‰‹çœ¼æ ‡å®šæµç¨‹")
        print("="*60)
        
        print("ğŸ“‹ æ ‡å®šæ­¥éª¤è¯´æ˜:")
        print("1. è¯·å°†çº¢è‰²ä¹é«˜ç§¯æœ¨æ”¾ç½®åœ¨æ‘„åƒå¤´è§†é‡å†…")
        print("2. ç³»ç»Ÿå°†æ‹æ‘„å›¾ç‰‡å¹¶è¯†åˆ«ç§¯æœ¨ä½ç½®")
        print("3. è¯·æµ‹é‡ç§¯æœ¨ç›¸å¯¹äºæœºæ¢°è‡‚åŸºåº§ä¸­å¿ƒç‚¹çš„ç‰©ç†åæ ‡")
        print("4. è¾“å…¥ç‰©ç†åæ ‡å®Œæˆæ ‡å®š")
        print("-"*60)
        
        # è·å–ç”¨æˆ·è¾“å…¥çš„ç‰©ç†åæ ‡
        try:
            print("è¯·è¾“å…¥çº¢è‰²ä¹é«˜ç§¯æœ¨çš„ç‰©ç†åæ ‡ (ç›¸å¯¹äºæœºæ¢°è‡‚åŸºåº§ä¸­å¿ƒç‚¹):")
            x = float(input("Xåæ ‡ (æ¯«ç±³): "))
            y = float(input("Yåæ ‡ (æ¯«ç±³): "))
            physical_coord = (x, y)
            
            print(f"ğŸ“ è¾“å…¥çš„ç‰©ç†åæ ‡: ({x}, {y}) æ¯«ç±³")
            
        except ValueError:
            print("âŒ è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            return False
        
        # æ‰§è¡Œæ ‡å®š
        if self.calibration.calibrate(physical_coord):
            self.is_calibrated = True
            print("âœ… æ‰‹çœ¼æ ‡å®šå®Œæˆï¼")
            return True
        else:
            print("âŒ æ‰‹çœ¼æ ‡å®šå¤±è´¥")
            return False
    
    def calculate_grasp_position(self, pixel_coord: Tuple[int, int]) -> Optional[Tuple[float, float, float]]:
        """
        è®¡ç®—æŠ“å–ä½ç½®
        
        Args:
            pixel_coord: åƒç´ åæ ‡
            
        Returns:
            Optional[Tuple[float, float, float]]: æŠ“å–ä½ç½® (x, y, z)
        """
        if not self.is_calibrated:
            print("âŒ å°šæœªå®Œæˆæ‰‹çœ¼æ ‡å®š")
            return None
        
        # å°†åƒç´ åæ ‡è½¬æ¢ä¸ºç‰©ç†åæ ‡
        physical_coord_origin = self.calibration.pixel_to_physical(pixel_coord)
        x,y=physical_coord_origin

        if  x >=100:
            x = x-5
            y = y +38

        elif -80<= x <100:
            x= x-10
            y = y+28
        else :
            x= x-23
            y=y+14
        

        physical_coord = (x,y)


        # åº”ç”¨ä½ç½®è¡¥å¿
        compensated_coord = apply_position_compensation(
            physical_coord[0], 
            physical_coord[1], 
            WORKTABLE_HEIGHT + GRIP_HEIGHT)
        
        # åº”ç”¨ä½ç½®è¡¥å¿
        compensated_coord = apply_position_compensation(
            physical_coord[0], 
            physical_coord[1], 
            WORKTABLE_HEIGHT + GRIP_HEIGHT
        )
        
        # print(f"ğŸ“ åƒç´ åæ ‡: {pixel_coord}")
        # print(f"ğŸ“ ç‰©ç†åæ ‡: {physical_coord}")
        # print(f"ğŸ“ è¡¥å¿ååæ ‡: {compensated_coord}")
        
        return compensated_coord
    
    def check_reachability(self, position: Tuple[float, float, float]) -> bool:
        """
        æ£€æŸ¥ä½ç½®æ˜¯å¦å¯è¾¾
        
        Args:
            position: ç›®æ ‡ä½ç½® (x, y, z)
            
        Returns:
            bool: æ˜¯å¦å¯è¾¾
        """
        # å°è¯•è¿›è¡Œé€†è¿åŠ¨å­¦è®¡ç®—
        try:
            joint_angles = inverse_kinematics(position)
            if joint_angles is None:
                return False
            
            # æ£€æŸ¥å…³èŠ‚è§’åº¦æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
            for i, angle in enumerate(joint_angles):
                if not (0 <= angle <= 180):
                    print(f"âš ï¸ å…³èŠ‚ {i+1} è§’åº¦ {angle:.2f}Â° è¶…å‡ºèŒƒå›´")
                    return False
            
            return True
            
        except Exception as e:
            print(f"âŒ é€†è¿åŠ¨å­¦è®¡ç®—å¤±è´¥: {e}")
            return False
    
    def execute_grasp_sequence(self, position: Tuple[float, float, float]) -> bool:
        """
        æ‰§è¡ŒæŠ“å–åºåˆ—
        
        Args:
            position: ç›®æ ‡ä½ç½® (x, y, z)
            
        Returns:
            bool: æŠ“å–æ˜¯å¦æˆåŠŸ
        """
        print(f"ğŸ¤– å¼€å§‹æ‰§è¡ŒæŠ“å–åºåˆ—ï¼Œç›®æ ‡ä½ç½®: {position}")
        
        try:
            # 1. è®¡ç®—é€†è¿åŠ¨å­¦
            joint_angles = inverse_kinematics(position)
            if joint_angles is None:
                print("âŒ é€†è¿åŠ¨å­¦è®¡ç®—å¤±è´¥ï¼Œä½ç½®ä¸å¯è¾¾")
                return False
            
            # 2. åº”ç”¨å…³èŠ‚è¡¥å¿
            compensated_angles = apply_joint_compensation(*joint_angles)
            
            print(f"ğŸ”§ åŸå§‹å…³èŠ‚è§’åº¦: {joint_angles}")
            print(f"ğŸ”§ è¡¥å¿åå…³èŠ‚è§’åº¦: {compensated_angles}")
            
            # 3. ç§»åŠ¨åˆ°å®‰å…¨é«˜åº¦
            safe_position = (position[0], position[1], position[2] + SAFE_HEIGHT)
            safe_angles = inverse_kinematics(safe_position)
            if safe_angles:
                safe_compensated = apply_joint_compensation(*safe_angles)
                self.robot.move_to_angles(*safe_compensated, GRIPPER_OPEN_ANGLE, MOVE_TIME)
                time.sleep(2)
            
            # 4. ç§»åŠ¨åˆ°æŠ“å–ä½ç½®
            self.robot.move_to_angles(*compensated_angles, GRIPPER_OPEN_ANGLE, MOVE_TIME)
            time.sleep(2)
            
            # 5. é—­åˆå¤¹æŒå™¨
            self.robot.move_to_angles(*compensated_angles, GRIPPER_CLOSE_ANGLE, MOVE_TIME)
            time.sleep(1)
            
            # 6. ç§»åŠ¨åˆ°å®‰å…¨é«˜åº¦
            if safe_angles:
                self.robot.move_to_angles(*safe_compensated, GRIPPER_CLOSE_ANGLE, MOVE_TIME)
                time.sleep(2)

            # 7. å›åˆ°åˆå§‹ä½ç½®
            self.robot.move_to_angles(0, 90, 180, 90, 0, GRIPPER_CLOSE_ANGLE, MOVE_TIME)
            time.sleep(2)

            # 8. é‡Šæ”¾å¤¹æŒå™¨
            self.robot.move_to_angles(0, 90, 180, 90, 0, GRIPPER_OPEN_ANGLE, MOVE_TIME)
            time.sleep(2)
            
            print("âœ… æŠ“å–åºåˆ—æ‰§è¡Œå®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ æŠ“å–åºåˆ—æ‰§è¡Œå¤±è´¥: {e}")
            return False
    
    def run_detection_loop(self):
        """
        è¿è¡Œæ£€æµ‹å’ŒæŠ“å–å¾ªç¯
        """
        print("\n" + "="*60)
        print("ğŸ”„ å¼€å§‹æ£€æµ‹å’ŒæŠ“å–å¾ªç¯")
        print("="*60)
        print("æŒ‰ 'q' é€€å‡ºå¾ªç¯ï¼ŒæŒ‰ 'r' é‡æ–°æ ‡å®š")
        
        if not self.is_calibrated:
            print("âŒ å°šæœªå®Œæˆæ‰‹çœ¼æ ‡å®šï¼Œè¯·å…ˆè¿›è¡Œæ ‡å®š")
            return
        
        while True:
            # è¯»å–æ‘„åƒå¤´ç”»é¢
            ret, frame = self.cap.read()
            if not ret:
                print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
                break
            
            # æ£€æµ‹çº¢è‰²ä¹é«˜ç§¯æœ¨
            pixel_coord = self.detect_red_lego(frame)
            
            # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
            if SHOW_CAMERA_FEED:
                display_frame = frame.copy()
                
                if pixel_coord:
                    # æ ‡è®°æ£€æµ‹åˆ°çš„ç§¯æœ¨
                    cv2.circle(display_frame, pixel_coord, 15, (0, 255, 0), 3)
                    cv2.putText(display_frame, f"Lego: {pixel_coord}", 
                               (pixel_coord[0] + 20, pixel_coord[1] - 20),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    
                    # è®¡ç®—ç‰©ç†åæ ‡
                    grasp_position = self.calculate_grasp_position(pixel_coord)
                    if grasp_position:
                        cv2.putText(display_frame, f"Pos: ({grasp_position[0]:.1f}, {grasp_position[1]:.1f})", 
                                   (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
                
                # æ·»åŠ æ§åˆ¶æç¤º
                cv2.putText(display_frame, "Press 'g' to grasp, 'q' to quit, 'r' to recalibrate", 
                           (10, display_frame.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                cv2.imshow("ä¹é«˜ç§¯æœ¨æ£€æµ‹", display_frame)
            
            # å¤„ç†é”®ç›˜è¾“å…¥
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('q'):
                print("ğŸ‘‹ ç”¨æˆ·é€€å‡ºæ£€æµ‹å¾ªç¯")
                break
            elif key == ord('r'):
                print("ğŸ”„ é‡æ–°æ ‡å®š")
                if self.perform_hand_eye_calibration():
                    continue
                else:
                    break
            elif key == ord('g') and pixel_coord:
                print("ğŸ¤– å¼€å§‹æŠ“å–...")
                
                # è®¡ç®—æŠ“å–ä½ç½®
                grasp_position = self.calculate_grasp_position(pixel_coord)
                if not grasp_position:
                    print("âŒ æ— æ³•è®¡ç®—æŠ“å–ä½ç½®")
                    continue
                
                # æ£€æŸ¥å¯è¾¾æ€§
                if not self.check_reachability(grasp_position):
                    print("âš ï¸ ç›®æ ‡ä½ç½®ä¸å¯è¾¾ï¼Œè·³è¿‡æ­¤æ¬¡æŠ“å–")
                    continue
                
                # æ‰§è¡ŒæŠ“å–
                if self.execute_grasp_sequence(grasp_position):
                    print("âœ… æŠ“å–æˆåŠŸï¼")
                    # ç­‰å¾…ä¸€æ®µæ—¶é—´å†è¿›è¡Œä¸‹ä¸€æ¬¡æ£€æµ‹
                    time.sleep(3)
                else:
                    print("âŒ æŠ“å–å¤±è´¥")
        
        cv2.destroyAllWindows()
    
    def run(self):
        """
        è¿è¡Œä¸»ç¨‹åº
        """
        print("ğŸš€ å¯åŠ¨ä¹é«˜ç§¯æœ¨è¯†åˆ«å’ŒæŠ“å–ç³»ç»Ÿ")
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        if not self.initialize_system():
            print("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
            return
        
        try:
            # æ‰§è¡Œæ‰‹çœ¼æ ‡å®š
            if not self.perform_hand_eye_calibration():
                print("âŒ æ‰‹çœ¼æ ‡å®šå¤±è´¥ï¼Œç¨‹åºé€€å‡º")
                return
            
            # è¿è¡Œæ£€æµ‹å’ŒæŠ“å–å¾ªç¯
            self.run_detection_loop()
            
        except KeyboardInterrupt:
            print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
        except Exception as e:
            print(f"âŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        finally:
            # æ¸…ç†èµ„æº
            self.cleanup()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("ğŸ§¹ æ­£åœ¨æ¸…ç†èµ„æº...")
        
        # å…³é—­æ‘„åƒå¤´
        self.close_camera()
        
        # å…³é—­æœºæ¢°è‡‚è¿æ¥
        if self.robot:
            self.robot.close_serial()
        
        # å…³é—­æ‰€æœ‰OpenCVçª—å£
        cv2.destroyAllWindows()
        
        print("âœ… èµ„æºæ¸…ç†å®Œæˆ")

def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("ğŸ¤– ä¹é«˜ç§¯æœ¨è¯†åˆ«å’ŒæŠ“å–ç³»ç»Ÿ")
    print("="*60)
    
    # åˆ›å»ºç³»ç»Ÿå®ä¾‹
    system = LegoGraspingSystem()
    
    # è¿è¡Œç³»ç»Ÿ
    system.run()

if __name__ == "__main__":
    main() 